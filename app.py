import streamlit as st
import os
from langchain_chroma import Chroma
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain.prompts import ChatPromptTemplate
from langchain.schema.runnable import RunnablePassthrough
from langchain.schema.output_parser import StrOutputParser

# --- ArayÃ¼z YapÄ±landÄ±rmasÄ± ---
st.set_page_config(
    page_title="Bitki HastalÄ±klarÄ± RAG Chatbotu (Gemini)",
    layout="wide"
)
st.title("ğŸŒ¿ Akbank GenAI Projesi: Bitki HastalÄ±klarÄ± Bilgi AsistanÄ±")
st.markdown("RAG (Retrieval Augmented Generation) mimarisi ile desteklenen bu chatbot, tarÄ±msal veri tabanÄ±ndan bilgi Ã§ekerek sorularÄ±nÄ±zÄ± yanÄ±tlar.")

# --- RAG BileÅŸenlerinin YÃ¼klenmesi (Ã–nbelleÄŸe AlÄ±nmÄ±ÅŸtÄ±r) ---

@st.cache_resource
def setup_rag_system():
    """
    RAG sisteminin tÃ¼m bileÅŸenlerini (DB, LLM, Zincir) yÃ¼kler ve Ã¶nbelleÄŸe alÄ±r.
    """
    # 1. API AnahtarÄ±nÄ±n KontrolÃ¼
    if "GEMINI_API_KEY" not in os.environ:
        st.error("LÃ¼tfen GEMINI_API_KEY ortam deÄŸiÅŸkenini ayarlayÄ±n ve uygulamayÄ± yeniden baÅŸlatÄ±n.")
        return None, None
    
    # 2. VektÃ¶r Veri TabanÄ±nÄ± YÃ¼kleme
    PERSIST_DIR = "./chroma_db"
    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
    
    try:
        # Chroma DB'nin daha Ã¶nce oluÅŸturulmuÅŸ olmasÄ± gerekir
        vectorstore = Chroma(
            persist_directory=PERSIST_DIR,
            embedding_function=embeddings
        )
        retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
    except Exception as e:
        st.error(f"VektÃ¶r Veri TabanÄ± yÃ¼klenirken hata oluÅŸtu. 'prepare_db.py' dosyasÄ±nÄ± Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±nÄ±zdan emin olun. Hata: {e}")
        return None, None

    # 3. LLM ve Prompt
    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.1)
    
    prompt_template = """
    Sen tarÄ±msal hastalÄ±klar konusunda uzman bir yapay zeka asistanÄ±sÄ±n. GÃ¶revin,
    kullanÄ±cÄ±nÄ±n sorusunu SADECE aÅŸaÄŸÄ±da verilen baÄŸlam (context) bilgisine gÃ¶re
    detaylÄ± ve bilgilendirici bir ÅŸekilde yanÄ±tlamaktÄ±r. EÄŸer verilen baÄŸlamda
    sorunun cevabÄ± YOKSA, "ÃœzgÃ¼nÃ¼m, bu sorunun cevabÄ± elimdeki bitki hastalÄ±klarÄ±
    bilgi tabanÄ±nda bulunmamaktadÄ±r." diye cevap vermelisin. CevaplarÄ±nÄ± TÃ¼rkÃ§e ver.

    --- BAÄLAM ---
    {context}
    ---

    KullanÄ±cÄ±nÄ±n Sorusu: {question}
    Cevap:
    """
    prompt = ChatPromptTemplate.from_template(prompt_template)
    
    # 4. LangChain RAG Zinciri
    rag_chain = (
        {"context": retriever, "question": RunnablePassthrough()}
        | prompt
        | llm
        | StrOutputParser()
    )
    
    return rag_chain, retriever

# RAG sistemini baÅŸlat
rag_chain, retriever = setup_rag_system()

# --- Chat ArayÃ¼zÃ¼ MantÄ±ÄŸÄ± ---

if rag_chain:
    # Mesaj geÃ§miÅŸini baÅŸlatma (Streamlit Session State)
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # GeÃ§miÅŸ mesajlarÄ± gÃ¶rÃ¼ntÃ¼leme
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # KullanÄ±cÄ± giriÅŸi
    if prompt_input := st.chat_input("Bitki hastalÄ±ÄŸÄ±nÄ±z hakkÄ±nda bilgi alÄ±n..."):
        # KullanÄ±cÄ± mesajÄ±nÄ± ekle
        st.session_state.messages.append({"role": "user", "content": prompt_input})
        with st.chat_message("user"):
            st.markdown(prompt_input)

        # Asistan cevabÄ±nÄ± al ve ekle
        with st.chat_message("assistant"):
            with st.spinner("Bilgi tabanÄ± taranÄ±yor ve cevap Ã¼retiliyor..."):
                # RAG zincirini Ã§alÄ±ÅŸtÄ±rma
                response = rag_chain.invoke(prompt_input)
                st.markdown(response)

        # CevabÄ± session state'e kaydet
        st.session_state.messages.append({"role": "assistant", "content": response})

        # *Opsiyonel: Hangi kaynaklarÄ± Ã§ektiÄŸini gÃ¶steren bir Sidebar ekleme*
        with st.sidebar:
            st.header("Ã‡ekilen Kaynaklar (Retrieval)")
            docs = retriever.invoke(prompt_input)
            for i, doc in enumerate(docs):
                st.subheader(f"Kaynak {i+1}")
                st.caption(f"Puan: {doc.metadata.get('_score', 'N/A')}")
                st.text(doc.page_content[:250] + "...") # Ä°lk 250 karakteri gÃ¶ster
