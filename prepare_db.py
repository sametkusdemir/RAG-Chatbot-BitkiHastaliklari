import os
from google import genai
from datasets import load_dataset
from langchain_chroma import Chroma
from langchain_community.document_loaders import DataFrameLoader
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter

# 1. API AnahtarÄ±nÄ±n KontrolÃ¼
# Projenizi Ã§alÄ±ÅŸtÄ±rabilmek iÃ§in GEMINI_API_KEY ortam deÄŸiÅŸkeni ayarlanmalÄ±dÄ±r.
if "GEMINI_API_KEY" not in os.environ:
    raise ValueError("LÃ¼tfen GEMINI_API_KEY ortam deÄŸiÅŸkenini ayarlayÄ±n.")

# 2. Veri Setini YÃ¼kleme (Hugging Face)
# ipranavks/agriculturaldatasetnew veri seti yÃ¼kleniyor.
# Sadece RAG iÃ§in gerekli olan 'Crop', 'Disease' ve 'Description' sÃ¼tunlarÄ±nÄ± alÄ±yoruz.
print("Veri seti yÃ¼kleniyor...")
dataset = load_dataset("ipranavks/agriculturaldatasetnew", split="train")
df = dataset.to_pandas()

# 3. Metinsel Veriyi HazÄ±rlama ve YÃ¼kleme (LangChain Loader)
# Her bir satÄ±rÄ± (bitki hastalÄ±ÄŸÄ±) RAG dokÃ¼manÄ± olarak hazÄ±rlÄ±yoruz.
# Source/Metadata bilgisi, chatbot'un hangi bilgiyi nereden Ã§ektiÄŸini gÃ¶rmesi iÃ§in Ã¶nemlidir.
df['content'] = df.apply(lambda row: f"Bitki: {row['Crop']}, HastalÄ±k AdÄ±: {row['Disease']}. AÃ§Ä±klama: {row['Description']}", axis=1)

# Veri setini LangChain'in anlayacaÄŸÄ± 'Document' formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼yoruz.
loader = DataFrameLoader(df, page_content_column="content")
documents = loader.load()
print(f"Toplam yÃ¼klÃ¼ dokÃ¼man sayÄ±sÄ±: {len(documents)}")

# 4. Metin ParÃ§alama (Text Splitting / Chunking)
# RAG performansÄ±nÄ± artÄ±rmak iÃ§in bÃ¼yÃ¼k metinleri kÃ¼Ã§Ã¼k parÃ§alara ayÄ±rÄ±yoruz.
# AyÄ±rÄ±cÄ± (splitter), en ideal parÃ§alama iÃ§in farklÄ± karakterleri deneyecektir.
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=100,
    separators=["\n\n", "\n", ".", " ", ""],
    length_function=len,
)
chunks = text_splitter.split_documents(documents)
print(f"ParÃ§alama sonrasÄ± oluÅŸan 'chunk' sayÄ±sÄ±: {len(chunks)}")

# 5. Embedding Modelini TanÄ±mlama
# Gemini'nin embedding modeli kullanÄ±lÄ±yor.
print("Embedding modeli yÃ¼kleniyor...")
embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")

# 6. VektÃ¶r Veri TabanÄ±nÄ± OluÅŸturma ve Kaydetme (ChromaDB)
# VektÃ¶rleÅŸtirme yapÄ±lÄ±yor ve ChromaDB'ye kaydediliyor.
# KalÄ±cÄ± bir disk depolama alanÄ± belirtiyoruz (persist_directory).
PERSIST_DIR = "./chroma_db"
print(f"VektÃ¶r veritabanÄ± {PERSIST_DIR} konumuna oluÅŸturuluyor ve kaydediliyor...")

vectorstore = Chroma.from_documents(
    documents=chunks,
    embedding=embeddings,
    persist_directory=PERSIST_DIR  # VeritabanÄ±nÄ± kaydet
)

print("\nğŸ‰ Veri tabanÄ± hazÄ±rlÄ±ÄŸÄ± tamamlandÄ±! ArtÄ±k RAG sorgularÄ± iÃ§in hazÄ±r.")
